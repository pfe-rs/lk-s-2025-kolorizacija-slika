{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e91be36b",
   "metadata": {},
   "source": [
    "# Trening generator + diskriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affe5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "import torch\n",
    "from skimage.color import lab2rgb\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "from generator import Generator\n",
    "from discriminator import Discriminator\n",
    "from BaseColor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bb3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_images_recursive(folder, extensions=('.JPEG', '.jpeg', '.jpg', '.JPG')):\n",
    "    img_paths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.endswith(extensions):\n",
    "                img_paths.append(os.path.abspath(os.path.join(root, f)))\n",
    "    return img_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b38ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset, BaseColor):\n",
    "    def __init__(self, root_dir, HW=(256, 256), extensions=('.JPEG', '.jpeg', '.jpg', '.JPG')):\n",
    "        Dataset.__init__(self)\n",
    "        BaseColor.__init__(self)\n",
    "        self.HW = HW\n",
    "        self.img_paths = find_images_recursive(root_dir, extensions)\n",
    "        print(f\"Pronađeno {len(self.img_paths)} slika u {root_dir} i podfolderima.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "\n",
    "        try:\n",
    "            # img_rgb_orig = load_img(img_path)\n",
    "\n",
    "            # tens_l, tens_ab = preprocess_img(img_rgb_orig, HW=self.HW)\n",
    "\n",
    "            # return tens_l, tens_ab\n",
    "            img_rgb_orig = load_img(img_path)\n",
    "\n",
    "            tens_orig_l, tens_rs_l = preprocess_img(img_rgb_orig, HW=self.HW)\n",
    "\n",
    "            img_rgb_rs = resize_img(img_rgb_orig, HW=self.HW, resample=Image.BILINEAR)\n",
    "            img_lab_rs = color.rgb2lab(img_rgb_rs).astype(np.float32)\n",
    "\n",
    "            img_ab_rs = img_lab_rs[:, :, 1:3]\n",
    "            tens_ab = torch.tensor(img_ab_rs).permute(2,0,1).float()\n",
    "\n",
    "            tens_l_norm = self.normalize_l(tens_rs_l.squeeze(0))\n",
    "            tens_ab_norm = self.normalize_ab(tens_ab)\n",
    "\n",
    "            return tens_l_norm, tens_ab_norm\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Preskačem fajl zbog greške: {img_path}\\nGreška: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab38a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronađeno 1300 slika u images_pfe/8/train.X1/n01440764 i podfolderima.\n"
     ]
    }
   ],
   "source": [
    "dataset = ColorizationDataset(\"images_pfe/8/train.X1/n01440764\", HW=(256, 256))\n",
    "input_l, target_ab = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167d235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 256, 256]), torch.Size([1, 256, 256]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ab.shape, input_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07499dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "HW = (256, 256) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bece57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "gen_opt = torch.optim.Adam(generator.parameters(), learning_rate, betas=(0.5, 0.999))\n",
    "disc_opt = torch.optim.Adam(discriminator.parameters(), learning_rate, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9759684",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a31a2",
   "metadata": {},
   "source": [
    "# Funkcije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feefc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tensor(np_img):\n",
    "    if isinstance(np_img, np.ndarray):\n",
    "        tensor = torch.from_numpy(np_img.astype(np.float32))\n",
    "        if tensor.ndim == 3:\n",
    "            tensor = tensor.permute(2, 0, 1)\n",
    "        elif tensor.ndim == 4:\n",
    "            tensor = tensor.permute(0, 3, 1, 2)\n",
    "        return tensor\n",
    "    else:\n",
    "        raise TypeError(\"Ulaz nije NumPy niz\")\n",
    "    \n",
    "def lab_to_rgb_image(input_l, out_ab):\n",
    "    base_color = BaseColor()\n",
    "    l_denorm = base_color.unnormalize_l(input_l)\n",
    "    ab_denorm = base_color.unnormalize_ab(out_ab)\n",
    "\n",
    "    lab = torch.cat([l_denorm, ab_denorm], dim=1)\n",
    "    lab_np = lab[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    rgb = lab2rgb(lab_np)\n",
    "    return rgb\n",
    "\n",
    "def safe_lab2rgb(lab):\n",
    "    lab_clipped = lab.copy()\n",
    "    lab_clipped[..., 0] = np.clip(lab_clipped[..., 0], 0, 100)     \n",
    "    lab_clipped[..., 1] = np.clip(lab_clipped[..., 1], -110, 110)  \n",
    "    lab_clipped[..., 2] = np.clip(lab_clipped[..., 2], -110, 110)  \n",
    "\n",
    "    rgb = lab2rgb(lab_clipped)\n",
    "    return rgb\n",
    "\n",
    "def show_images(real, fake):\n",
    "    real = real.permute(1, 2, 0).detach().cpu().numpy()\n",
    "    fake = fake.permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(real)\n",
    "    axs[0].set_title(\"Originalna slika\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(fake)\n",
    "    axs[1].set_title(\"Generisana slika\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876a17f",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b47a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "checkpoint_path = 'checkpoint.pth1'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    discriminator.load_state_dict(checkpoint[\"discriminator_state_dict\"])\n",
    "    gen_opt.load_state_dict(checkpoint['optimizer_g_dict'])\n",
    "    disc_opt.load_state_dict(checkpoint['optimizer_d_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    global_step = checkpoint.get('global_step', 0)\n",
    "    print(f\"Nastavljam od epohe {start_epoch}, global_step = {global_step}\")\n",
    "else:\n",
    "    global_step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f061e9",
   "metadata": {},
   "source": [
    "# Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5806d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "LAMBDA = 100\n",
    "\n",
    "def delta_e_loss(input_l, ab_pred, ab_true):\n",
    "    base_color = BaseColor()\n",
    "    l_denorm = base_color.unnormalize_l(input_l)\n",
    "    ab_pred_denorm = base_color.unnormalize_ab(ab_pred)\n",
    "    ab_true_denorm = base_color.unnormalize_ab(ab_true)\n",
    "\n",
    "    lab_pred = torch.cat([l_denorm, ab_pred_denorm], dim=1)\n",
    "    lab_true = torch.cat([l_denorm, ab_true_denorm], dim=1)\n",
    "\n",
    "    delta_e = torch.norm(lab_pred - lab_true, dim=1)  \n",
    "    return delta_e.mean()\n",
    "\n",
    "def colorfulness_loss(ab_pred):\n",
    "    return -ab_pred.abs().mean()\n",
    "\n",
    "def gan_loss(disc_generated_output):\n",
    "    gan_loss = bce_loss(torch.ones_like(disc_generated_output), disc_generated_output)\n",
    "    return gan_loss\n",
    "\n",
    "def generator_loss(input_l,ab_pred,ab_true,disc_generated_output):\n",
    "    color_loss = delta_e_loss(input_l, ab_pred, ab_true)\n",
    "    boost_color = colorfulness_loss(ab_pred)\n",
    "    gan_loss = gan_loss(disc_generated_output)\n",
    "    loss = color_loss + 0.1 * boost_color + gan_loss\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4002724",
   "metadata": {},
   "source": [
    "# Diskriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac7ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "LAMBDA = 100\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = bce_loss(disc_real_output, torch.ones_like(disc_real_output))\n",
    "    fake_loss = bce_loss(disc_generated_output, torch.zeros_like(disc_generated_output))\n",
    "    total_disc_loss = real_loss + fake_loss\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3d673c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m global_step = \u001b[32m0\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[43mG\u001b[49m.train()\n\u001b[32m     11\u001b[39m     epoch_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     12\u001b[39m     start_time = time.time()\n",
      "\u001b[31mNameError\u001b[39m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Conversion from CIE-LAB, via XYZ to sRGB color space resulted in .* negative Z values.*\")\n",
    "\n",
    "epoch_losses = [] \n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    G.train()\n",
    "    epoch_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, (input_l, target_ab) in enumerate(dataloader):\n",
    "        input_l = input_l.to(device)        \n",
    "        target_ab = target_ab.to(device) \n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        output_ab = G(input_l)         \n",
    "\n",
    "        color_loss = delta_e_loss(input_l, output_ab, target_ab)\n",
    "        boost_color = colorfulness_loss(output_ab)\n",
    "        loss = color_loss + 0.1 * boost_color\n",
    "        loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if global_step % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake_rgb_np = lab_to_rgb_image(input_l, output_ab)\n",
    "                real_rgb_np = lab_to_rgb_image(input_l, target_ab)\n",
    "\n",
    "                fake_rgb = numpy_to_tensor(fake_rgb_np).to(device)  \n",
    "                real_rgb = numpy_to_tensor(real_rgb_np).to(device)\n",
    "\n",
    "                fake_rgb_vis = fake_rgb.clone().clamp(0, 1)\n",
    "                real_rgb_vis = real_rgb.clone().clamp(0, 1)\n",
    "\n",
    "            N = min(4, fake_rgb_vis.size(0))\n",
    "            if fake_rgb_vis.ndim == 3:  \n",
    "                fake_rgb_vis = fake_rgb_vis.unsqueeze(0)  \n",
    "            if real_rgb_vis.ndim == 3:\n",
    "                real_rgb_vis = real_rgb_vis.unsqueeze(0)\n",
    "    \n",
    "            fake_rgb_vis_uint8 = (fake_rgb_vis * 255).clamp(0, 255).to(torch.uint8)\n",
    "            real_rgb_vis_uint8 = (real_rgb_vis * 255).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "            if global_step % 1000 == 0:\n",
    "                show_images(real_rgb_vis_uint8[0], fake_rgb_vis_uint8[0])\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    epoch_losses.append(avg_epoch_loss) \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1} završena. Prosečni loss: {avg_epoch_loss:.4f}. Vreme epohe: {elapsed:.1f} s\")\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': G.state_dict(),\n",
    "        'optimizer_state_dict':g_optimizer.state_dict(),\n",
    "        'global_step': global_step\n",
    "    }, checkpoint_path)\n",
    "\n",
    "print(\"Trening završen.\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(start_epoch + 1, start_epoch + 1 + len(epoch_losses)), epoch_losses, marker='o')\n",
    "plt.title('Loss tokom epoha')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Prosečni loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c4e9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256, 256]), torch.Size([2, 256, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_l.shape,target_ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d556500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5000), tensor(-0.4994), tensor(0.5773), tensor(-0.2923))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_l.max(),input_l.min(),target_ab.max(),target_ab.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1baffaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 256, 256]), torch.Size([1, 2, 256, 256]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_l = input_l.unsqueeze(0)    # (1, 1, 256, 256)\n",
    "target_ab = target_ab.unsqueeze(0)                # (1, 2, 256, 256)\n",
    "input_l.shape, target_ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fdb614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_l = input_l.to(device)        \n",
    "target_ab = target_ab.to(device)\n",
    "fake_ab = generator(input_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2583f10",
   "metadata": {},
   "source": [
    "# Potpun trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8397197f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 256, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1c1ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1463, grad_fn=<MaxBackward1>),\n",
       " tensor(-0.1693, grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_ab.max(),fake_ab.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46f4155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_lab = torch.cat([input_l, fake_ab], dim=1) \n",
    "real_lab = torch.cat([input_l, target_ab], dim=1)\n",
    "input_rgb = input_l.repeat(1, 3, 1, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71fb5ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 256, 256]),\n",
       " torch.Size([1, 3, 256, 256]),\n",
       " torch.Size([1, 3, 256, 256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_lab.shape,real_lab.shape,input_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66580274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "disc_real_out = discriminator(input_rgb, real_lab)\n",
    "disc_fake_out = discriminator(input_rgb, fake_lab.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54093bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 30, 30]), tensor(-0.9526, grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_fake_out.shape, disc_real_out.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c51e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4242, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = discriminator_loss(disc_real_out, disc_fake_out)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a625dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pocetak treninga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PFE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Conversion from CIE-LAB, via XYZ to sRGB color space resulted in .* negative Z values.*\")\n",
    "\n",
    "epoch_losses = [] \n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    epoch_gen_loss = 0.0\n",
    "    epoch_disc_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    print(\"pocetak treninga\")\n",
    "    for batch_idx, (input_l, target_ab) in enumerate(dataloader):\n",
    "        print(\"prva epoha\")\n",
    "        input_l = input_l.to(device)        \n",
    "        target_ab = target_ab.to(device)\n",
    "\n",
    "\n",
    "        fake_ab = generator(input_l)\n",
    "        input_l = input_l.unsqueeze(0)    # (1, 1, 256, 256)\n",
    "        target_ab = target_ab.unsqueeze(0) # 1 2 256 256\n",
    "        fake_lab = torch.cat([input_l, fake_ab], dim=1) \n",
    "        real_lab = torch.cat([input_l, target_ab], dim=1)\n",
    "        input_rgb = input_l.repeat(1, 3, 1, 1)  \n",
    "        \n",
    "        # trening diskriminatora\n",
    "        \n",
    "        disc_real_out = discriminator(input_rgb, real_lab)\n",
    "        disc_fake_out = discriminator(input_rgb, fake_lab.detach())\n",
    "\n",
    "        d_loss = discriminator_loss(disc_real_out, disc_fake_out)\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "        d_loss.backward()\n",
    "        disc_opt.step()\n",
    "\n",
    "    #   trening generatora\n",
    "        disc_fake_out = discriminator(input_rgb, fake_lab)\n",
    "        g_loss = generator_loss(input_l,target_ab,fake_ab,disc_fake_out)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        g_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        epoch_gen_loss += g_loss.item()\n",
    "        epoch_disc_loss += d_loss.item()\n",
    "\n",
    "\n",
    "        if global_step % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                fake_rgb_np = lab_to_rgb_image(input_l, fake_ab)\n",
    "                real_rgb_np = lab_to_rgb_image(input_l, target_ab)\n",
    "\n",
    "                fake_rgb = numpy_to_tensor(fake_rgb_np).to(device)  \n",
    "                real_rgb = numpy_to_tensor(real_rgb_np).to(device)\n",
    "\n",
    "                fake_rgb_vis = fake_rgb.clone().clamp(0, 1)\n",
    "                real_rgb_vis = real_rgb.clone().clamp(0, 1)\n",
    "\n",
    "            if fake_rgb_vis.ndim == 3:  \n",
    "                fake_rgb_vis = fake_rgb_vis.unsqueeze(0)  \n",
    "            if real_rgb_vis.ndim == 3:\n",
    "                real_rgb_vis = real_rgb_vis.unsqueeze(0)\n",
    "\n",
    "            fake_rgb_vis_uint8 = (fake_rgb_vis * 255).clamp(0, 255).to(torch.uint8)\n",
    "            real_rgb_vis_uint8 = (real_rgb_vis * 255).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "            if global_step % 1000 == 0:\n",
    "                show_images(real_rgb_vis_uint8[0], fake_rgb_vis_uint8[0])\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], \"\n",
    "                  f\"Gen Loss: {g_loss.item():.4f}, Disc Loss: {d_loss.item():.4f}, \"\n",
    "                  f\"GAN: {g_loss.item():.4f}\")\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    avg_gen_loss = epoch_gen_loss / len(dataloader)\n",
    "    avg_disc_loss = epoch_disc_loss / len(dataloader)\n",
    "    epoch_losses.append(avg_gen_loss) \n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1} završena. G-Loss: {avg_gen_loss:.4f}, D-Loss: {avg_disc_loss:.4f}. Vreme: {elapsed:.1f} s\")\n",
    "\n",
    "    # ============ 5. ČUVANJE MODEL STATE ============\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'discriminator_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_g': gen_opt.state_dict(),\n",
    "        'optimizer_d': disc_opt.state_dict(),\n",
    "        'global_step': global_step\n",
    "    }, checkpoint_path)\n",
    "\n",
    "print(\"Trening završen.\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(start_epoch + 1, start_epoch + 1 + len(epoch_losses)), epoch_losses, marker='o')\n",
    "plt.title('Generator Loss tokom epoha')\n",
    "plt.xlabel('Epoha')\n",
    "plt.ylabel('Prosečni generator loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e6de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
